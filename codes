#code for coordinator
import mysql.connector

def get_switches():
    # Connect to the Switches DB (assuming MySQL for this example)
    db = mysql.connector.connect(s
        host="localhost",
        user="user",
        password="password",
        database="switches_db"
    )
    cursor = db.cursor()
    cursor.execute("SELECT ip FROM switches")
    switches = cursor.fetchall()
    db.close()
    return [switch[0] for switch in switches]

def publish_tasks(switches):
    credentials = pika.PlainCredentials('morjana', '217034')
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost', 5672, '/', credentials))
    channel = connection.channel()
    channel.queue_declare(queue='tasks_queue')

    for switch in switches:
        channel.basic_publish(exchange='', routing_key='tasks_queue', body=switch)
    
    connection.close()

if _name_ == "_main_":
    switches = get_switches()
    publish_tasks(switches)
----------------------------------------------------------------------
#cpde for collector
import pika
import threading
from pysnmp.hlapi import *
from influxdb_client import InfluxDBClient, Point, WritePrecision
from datetime import datetime

def get_temperature(switch_ip):
    iterator = getCmd(
        SnmpEngine(),
        CommunityData('public', mpModel=0),
        UdpTransportTarget((switch_ip, 16100)),  # Use the simulator's port
        ContextData(),
        ObjectType(ObjectIdentity('1.3.6.1.4.1.9.9.13.1.3.1.3.0'))
    )
    
    error_indication, error_status, error_index, var_binds = next(iterator)
    
    if error_indication or error_status:
        return None
    
    for var_bind in var_binds:
        return float(var_bind[1])

def write_to_influxdb(switch_ip, temperature):
    client = InfluxDBClient(url="http://localhost:8086", token="myInfluxDBToken123", org="myOrg")
    write_api = client.write_api(write_options=SYNCHRONOUS)
    point = Point("temperature")\
        .tag("switch", switch_ip)\
        .field("value", temperature)\
        .time(datetime.utcnow(), WritePrecision.NS)
    write_api.write(bucket="temperature_db", record=point)
    client.close()

def process_task(ch, method, properties, body):
    switch_ip = body.decode()
    temperature = get_temperature(switch_ip)
    if temperature is not None:
        write_to_influxdb(switch_ip, temperature)
    ch.basic_ack(delivery_tag=method.delivery_tag)

def start_consumer():
    credentials = pika.PlainCredentials('morjana', '217034')
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost', 5672, '/', credentials))
    channel = connection.channel()
    channel.queue_declare(queue='tasks_queue')

    channel.basic_qos(prefetch_count=1)
    channel.basic_consume(queue='tasks_queue', on_message_callback=process_task)
    channel.start_consuming()

if _name_ == "_main_":
    threads = []
    for _ in range(4):  # Number of threads can be adjusted
        thread = threading.Thread(target=start_consumer)
        thread.start()
        threads.append(thread)

    for thread in threads:
        thread.join()
-----------------------------------------------------------------
#DataBase
CREATE DATABASE monitoring;
USE monitoring;

CREATE TABLE switches (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    ip_address VARCHAR(255) NOT NULL
);

INSERT INTO switches (name, ip_address) VALUES ('Switch1', '127.0.0.1:1024');
INSERT INTO switches (name, ip_address) VALUES ('Switch2', '127.0.0.1:1025');
